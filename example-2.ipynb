{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Astronomy Data Analysis with AI Techniques\n",
    "\n",
    "This notebook demonstrates how to use AI algorithms to analyze astronomical data. We'll classify galaxies and detect exoplanets using machine learning techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic dataset representing galaxy data\n",
    "def generate_galaxy_data(n_samples=10000):\n",
    "    np.random.seed(42)\n",
    "    X, y = make_classification(n_samples=n_samples, n_features=10, n_informative=5, n_redundant=2, n_clusters_per_class=1, n_classes=3)\n",
    "    columns = [f'feature_{i}' for i in range(X.shape[1])]\n",
    "    df = pd.DataFrame(X, columns=columns)\n",
    "    df['label'] = y\n",
    "    return df\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "df_galaxy = generate_galaxy_data()\n",
    "X_galaxy = df_galaxy.drop('label', axis=1)\n",
    "y_galaxy = df_galaxy['label']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_galaxy_train, X_galaxy_test, y_galaxy_train, y_galaxy_test = train_test_split(X_galaxy, y_galaxy, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler_galaxy = StandardScaler()\n",
    "X_galaxy_train_scaled = scaler_galaxy.fit_transform(X_galaxy_train)\n",
    "X_galaxy_test_scaled = scaler_galaxy.transform(X_galaxy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality reduction using PCA\n",
    "pca_galaxy = PCA(n_components=2)\n",
    "X_galaxy_train_pca = pca_galaxy.fit_transform(X_galaxy_train_scaled)\n",
    "X_galaxy_test_pca = pca_galaxy.transform(X_galaxy_test_scaled)\n",
    "\n",
    "# Visualization of the data using PCA components\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=X_galaxy_train_pca[:, 0], y=X_galaxy_train_pca[:, 1], hue=y_galaxy_train, palette='viridis', s=50)\n",
    "plt.title('PCA of Galaxy Data')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.legend(title='Galaxy Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering using KMeans to identify galaxy types\n",
    "kmeans_galaxy = KMeans(n_clusters=3, random_state=42)\n",
    "y_galaxy_train_clusters = kmeans_galaxy.fit_predict(X_galaxy_train_pca)\n",
    "y_galaxy_test_clusters = kmeans_galaxy.predict(X_galaxy_test_pca)\n",
    "\n",
    "# Visualization of the clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=X_galaxy_train_pca[:, 0], y=X_galaxy_train_pca[:, 1], hue=y_galaxy_train_clusters, palette='viridis', s=50)\n",
    "plt.title('KMeans Clustering of Galaxy Data')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.legend(title='Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification using Random Forest to identify galaxy types\n",
    "clf_galaxy = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_galaxy.fit(X_galaxy_train_scaled, y_galaxy_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_galaxy_pred = clf_galaxy.predict(X_galaxy_test_scaled)\n",
    "print(classification_report(y_galaxy_test, y_galaxy_pred, target_names=['Galaxy Type 1', 'Galaxy Type 2', 'Galaxy Type 3']))\n",
    "print(confusion_matrix(y_galaxy_test, y_galaxy_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importances_galaxy = pd.Series(clf_galaxy.feature_importances_, index=X_galaxy.columns)\n",
    "feature_importances_galaxy.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=feature_importances_galaxy, y=feature_importances_galaxy.index)\n",
    "plt.title('Feature Importances in Galaxy Classification')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic dataset representing exoplanet data\n",
    "def generate_exoplanet_data(n_samples=10000):\n",
    "    np.random.seed(42)\n",
    "    X, y = make_classification(n_samples=n_samples, n_features=10, n_informative=5, n_redundant=2, n_clusters_per_class=1, n_classes=2)\n",
    "    columns = [f'feature_{i}' for i in range(X.shape[1])]\n",
    "    df = pd.DataFrame(X, columns=columns)\n",
    "    df['label'] = y\n",
    "    return df\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "df_exoplanet = generate_exoplanet_data()\n",
    "X_exoplanet = df_exoplanet.drop('label', axis=1)\n",
    "y_exoplanet = df_exoplanet['label']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_exoplanet_train, X_exoplanet_test, y_exoplanet_train, y_exoplanet_test = train_test_split(X_exoplanet, y_exoplanet, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler_exoplanet = StandardScaler()\n",
    "X_exoplanet_train_scaled = scaler_exoplanet.fit_transform(X_exoplanet_train)\n",
    "X_exoplanet_test_scaled = scaler_exoplanet.transform(X_exoplanet_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification using Random Forest to detect exoplanets\n",
    "clf_exoplanet = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_exoplanet.fit(X_exoplanet_train_scaled, y_exoplanet_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_exoplanet_pred = clf_exoplanet.predict(X_exoplanet_test_scaled)\n",
    "print(classification_report(y_exoplanet_test, y_exoplanet_pred, target_names=['No Exoplanet', 'Exoplanet']))\n",
    "print(confusion_matrix(y_exoplanet_test, y_exoplanet_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importances_exoplanet = pd.Series(clf_exoplanet.feature_importances_, index=X_exoplanet.columns)\n",
    "feature_importances_exoplanet.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=feature_importances_exoplanet, y=feature_importances_exoplanet.index)\n",
    "plt.title('Feature Importances in Exoplanet Detection')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
